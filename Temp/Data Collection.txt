DATA COLLECTION
+++++++++++++++

+++++++++++++++++++++++++++++++++++++++++++
PERFORMANCE TUNING DATA COLLECTION
++++++++++++++++++++++++++++++++++++++++++
Perforamce 

1] Slow  - DB  AWR,ASH,OSwatcher,CHM(used for Windows)
           SQL - 1046,tkproof
		   
2] Hang  - DB  Global System state dump and Hang analysis <Please check the SGA Size><check alter log already if it has already dumped>,   
           SQL  Process state dump.            "
           SQL - Tuning advisor ()
3] RAC Wait events -
           COllect the AWR report from all the nodes in same time.1hr or 60min or less
           LMS - process responsible for cache fusion.
		   gc lost blocks diagnostic
4]DFS Lock Handle- 
           log file sync lfsdiag.sql
		   
5] 

--
SQL 
SQLT 215187.1
224270.1
sanman.krishnamurthy
1] EXECTUION PLAN CHANGE - bug fix can cause these [OFE - optimiser_ parameter to previous version ]
   10046, AWR , sqlt, v$active session history 
2] Data Change
   10046 AWR ,sqlt,
3] Resource 
   OS watcher AWR

---
1] - Please upload optach lsinventry -detail
 
2] - Identify a couple of session where the "ipc send completion sync" is 
   occuring..
 
 select SPID,EVENT,P1,P2,P3,WAIT_TIME,SECONDS_IN_WAIT,STATE from 
 v$session , v$process where addr=paddr and event like '%IPC send completion 
 sync%' ;
 
 
3] - set the below event in that session and allow tracing to continue for 
 around 5 minutes.one can repeat it for around 3 SPIDS identified from above 
 sql.
 
 sqlplus /as sysdba
 oradebug setospid <SPID from above sql>
 oradebug unlimit
 oradebug errorstack level 3
 oradebug event=10402 trace name context forever, level 1
 oradebug event=10046 trace name context forever, level 12
 oradebug errorstack level 3
 
4] - set the event OFF in the session after 5 minutes..
 
 oradebug errorstack level 3
 oradebug event=10402 trace name context off
 oradebug event=10046 trace name context off
 oradebug errorstack level 3
 
5] - gather oswatcher at interval of 30 seconds.make sure to trace the 
 interconnect.

6] - gather AWR reports from all the rac instances at interval of 25 minutes.




+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
STORAGE DATA COLLECTION 
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
COLNING
+++++++
There is various storage cloning methods and technologies used by different storage vendors. As long as the cloning techology creates consistent snapshots of all the disks in an ASM disk group then the diskgroup based on the copied LUNs can be mounted at an alternate site.

- EMC CLARiiON SnapView and MirrorView (also known as BCV copy)
- Hitachi Data Systems (HDS): Universal Storage Platform Replication Software
- IBM FlashCopy

Most common disk cloning technologies is mentioned in the following link. The documents specific for each vendor also explains the best practices when creating the disk copies.

http://www.oracle.com/technetwork/database/index-100339.html

Note: The POC and Procedure of the storage clone comes from the respective Vendor.


DISABLE DNFS
++++++++++++
DNFS is enabled by default and been used automatically in 12C(DNFS is disabled in 11.2)
because It has higher priority than regular NFS client.

Please execute command and provide the output.
$ pwd
$ cd $ORACLE_HOME/lib
ls -l *odm*

To disable DHFS , shutdown the DB and do:
(official way): cd $ORACLE_HOME/rdbms/lib; make -f ins_rdbms.mk dnfs_off ioracle
(non-official): rename this file:
Example:

# ll $ORACLE_HOME/rdbms/lib/odm/
total 100
-rw-r--r--. 1 oracle oinstall 96003 Jul 16 23:12 libnfsodm12.so
# cd $ORACLE_HOME/rdbms/lib/odm/
# mv libnfsodm12.so libnfsodm12.so.OLD

Now start the instance, and you should not see the Direct NFS lines in the
alert.log

This will work only when it is in this half/disabled/enabled state.
Please follow the first method and use second method for debug/rediscovery
purposes.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
RAC DATA COLLECTION
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Would you please clarify me below queries to start troubleshooting.     
1. How many nodes in cluster..?     
      Output of   1.crsctl stat res -t  
                  2. crsctl check crs  
                  3. ps -ef | grep init  
	  4. ps -ef | grep d.bin    
	  
2. Which node is having the issue..? 
   node name please..?
   
3. Get me exact issue date and time.     

4.How was the resource utilization on the system when crash happened?     
To check this, please get me OSW logs that covering issue time     
Note.301137.1 OS Watcher Black Box User Guide (Doc ID 301137.1)     

5. who -b command output from all the nodes.     

6. Was there any recent changes happened..?     

7.Did you/your sysadmin see any errors in the OS messages file?   
  Please upload sys logs that cover issue time    

8. Please upload the diag collection from ALL the nodes  . 
The crs log files using TFA:         

9. Upload database alert logs     
10. Please get me sys logs messages     
11. What is the current status.?     
12. What is the status of DIAGWAIT     crsctl get css diagwait     Regards,  Rakesh  
 

 









PLease upload the following information
Please upload diagcollection logs / TFA logs from all the nodes.

1) $GI_HOME/tfa/bin/tfactl diagcollect -from <date/time> -to <date/time>
where <date/time> is in "MMM/dd/yyyy hh:mm:ss" format; for example, "Jul/1/2014 21:00:00"
Specify the "from time" to be 4 hours before and the "to time" to be 4 hours after the time of error.
The TFA Collector will extract and collect the trace and log information written between the "from time" and "to time" from files.

Issue "$GI_HOME/tfa/bin/tfactl diagcollect -h" to get the help page for tfactl command.

Upload all files that TFA collector creates to SR.
CRS 10gR2/ 11gR1/ 11gR2 Diagnostic Collection Guide [Document 330358.1]

* For 11gR2
        o Execute <GRID_HOME>/bin/diagcollection.sh as Root user

Note 1513912.1 - TFA Collector - Tool for Enhanced Diagnostic Gathering and start TFA


2) Upload AWR reports from all instances of the problem database to SR.
      The time period for AWR report should not be greater than 1 hour and preferably 30 minutes during the time of performance problem.
      Get one AWR report just prior to the database hang started and another just after the database hang started (Get the AWR reports if they are available).


	  3) Upload ASH reports from all instances of the problem database to SR.
     ASH report can cover shorter time period like 10 minutes, so upload multiple ASH reports covering 10 minutes just prior to the hang and just after the hang.


4) Upload ADM reports from all instances of the problem database to SR.


5) Set your environment to the GI home.
   opatch lsinventory

6)Set your environment to the RDBMS home.
   opatch lsinventory


7)Provide your OSW (OSWatcher) output, for the one hour timeframe leading up to and including the problem for EACH node.
   If you did not have OSWatcher running at the time of the instance hangs, you won't be able to provide the oswatcher .dat files.
 
 OSWatcher gathers OS data such as vmstat, iostat, netstat, mpstat, in files that each hold 1 hour of data.
 If you do not have OSWatcher running, then please set it up per OS Watcher Black Box User Guide (Doc ID 301137.1).
 We recommend configuring OSWatcher with an interval of 20 seconds and a retention of at least 2 days.
 Be sure to setup the private.net (traceroute of the private interconnects) when setting up OSWatcher.
 The OSWatcher tar file you downloaded includes an Exampleprivate.net. You can make your private.net file from the OS specific
 sample info within Exampleprivate.net.  Once you have created private.net be sure to give it execute permissions.


 The  relevant  notes are:
 OSWatcher Black Box (Includes: [Video]) (Doc ID 301137.1)
 OS Watcher User's Guide (Doc ID 1531223.1)
 OSWatcher Black Box Analyzer User Guide (Doc ID 461053.1)
 How To Start OSWatcher Black Box (OSWBB) Every System Boot (Doc ID 580513.1)
